---
title: "Neural Networks"
format:
  html:
    toc: true
    toc-location: right
    toc-depth: 5
    number-sections: false
    code-fold: false
    sidebar: true
    collapse-level: 4
editor: source
editor_options: 
  chunk_output_type: console
knitr:
  opts_chunk: 
    message: false
    warning: false
    code-fold: show
    include: true
    collapse: true
    eval: true
    fig.show: hold
execute:
  callr: false
    
---

# Introduction

We are going to continue with our exploration of the biology of obesity. Let's see if we can improve our predictive using the less well-known genes by using neural networks. 

We will train a forward feedback network, also known as multilayer perceptrons (MLPs).

## Load packages
```{r}
#| label: load-packages
#| eval: false


# load packages
rm(list=ls())
library(tidyverse)
#library(ggcorrplot)
#library(glmnet)
library(fastDummies)
library(pROC)
library(class)


library(reticulate)
use_condaenv("r-reticulate", required = TRUE)
# reticulate::py_discover_config()
# # Load the clinical data
data_obesity <- read_csv("data/data-obesity.csv") 

library(keras)
use_python("/Users/olga.hrydziuszko/miniconda3/envs/r-reticulate/bin/python")
# Load gene expression data
data_expr <- read_csv("data/data-obesity-genes.csv")
genes_all <- colnames(data_expr)[-1]  # Exclude the 'id' column

# Genes
gens_known <- c("FTO", "MC4R", "LEP")
genes_other <- setdiff(genes_all, gens_known)

```


## Split Data

```{r}
#| label: split-data
#| eval: false
#| warning: false
#| message: false
#| code-fold: false

# join gene expression data with clinical data
data <- data_obesity %>%
  left_join(data_expr, by = "id") %>%
  dplyr::select("obese", all_of(genes_other)) %>%
  na.omit()

# select top 100 genes based on variance
# Calculate variance for each gene
gene_vars <- data %>%
  select(-obese) %>%
  summarise(across(everything(), var)) %>%
  pivot_longer(everything(), names_to = "gene", values_to = "variance")

# # Select top 100 most variable genes
# top_genes <- gene_vars %>%
#   arrange(desc(variance)) %>%
#   slice_head(n = 100) %>%
#   pull(gene)

# # Subset the data to use only top 100 genes
# data <- data %>%
#   select(obese, all_of(top_genes))

# three-way split: train (60%), validation (20%), test (20%)
set.seed(123)
n <- nrow(data)
idx <- sample(seq_len(n))
idx_train <- idx[1:floor(0.6 * n)]
idx_valid <- idx[(floor(0.6 * n) + 1):floor(0.8 * n)]
idx_test  <- idx[(floor(0.8 * n) + 1):n]

data_train <- data[idx_train, ]
data_valid <- data[idx_valid, ]
data_test  <- data[idx_test, ]

# To keep focus on the important parts, we will skip feature engineering
# and we will just scale all data
x_train <- data_train %>%
  dplyr::select(-obese) %>%
  as.matrix() %>%
  scale()

x_valid <- data_valid %>%
  dplyr::select(-obese) %>%
  as.matrix() %>%
  scale()

x_test <- data_test %>%
  dplyr::select(-obese) %>%
  as.matrix() %>%
  scale()

# Separate and format target variable
y_train <- data_train$obese
y_train <- ifelse(y_train == "Yes", 1, 0) 

y_valid <- data_valid$obese
y_valid <- ifelse(y_valid == "Yes", 1, 0)

y_test <- data_test$obese
y_test <- ifelse(y_test == "Yes", 1, 0)

```

## Train Feedforward Neural Network

Let's fit a simple feedforward neural network using the Keras package. We will use a sequential model with dense layers, and compile it with the Adam optimizer and binary crossentropy loss function.

In particular, we will use a simple architecture with two hidden layers, and we will use dropout to prevent overfitting. 

This neural network is well-suited for the obesity classification task because:
- It accepts high-dimensional gene expression input, which can contain complex, nonlinear patterns.
- The first dense layer with 64 ReLU units learns rich feature representations from gene data.
- Dropout layers (0.3 and 0.2) help prevent overfitting, which is critical when working with many features and relatively few samples.
- The final dense layer uses a sigmoid activation to output a probability of obesity (binary classification).
- This architecture is flexible and efficient enough to model subtle interactions between genes that simpler models might miss.

```{r}
#| label: keras-model
#| eval: false
#| message: false
#| warning: false

# Define model
model <- keras_model_sequential() %>%
  layer_dense(units = 64, activation = "relu", input_shape = ncol(x_train)) %>%
  layer_dropout(0.3) %>%
  layer_dense(units = 32, activation = "relu") %>%
  layer_dropout(0.2) %>%
  layer_dense(units = 1, activation = "sigmoid")

# Compile model
model %>% compile(
  optimizer = "adam",
  loss = "binary_crossentropy",
  metrics = c("accuracy")
)

# Fit model
history <- model %>% fit(
  x_train, y_train,
  epochs = 10,
  batch_size = 32,
  validation_data = list(x_valid, y_valid),
  verbose = 1
)

```



```{r}
#| eval: false
#| include: false
#| message: false
#| warning: false

# Define model
# model <- keras_model_sequential() %>%
#   layer_dense(units = 64, activation = "relu", input_shape = ncol(x_train)) %>%
#   layer_dropout(0.3) %>%
#   layer_dense(units = 32, activation = "relu") %>%
#   layer_dropout(0.2) %>%
#   layer_dense(units = 1, activation = "sigmoid")


# Define model with L2 regularization
model <- keras_model_sequential() %>%
  layer_dense(units = 64, activation = "relu", input_shape = ncol(x_train),
              kernel_regularizer = regularizer_l2(0.001)) %>%
  layer_dropout(rate = 0.3) %>%
  layer_dense(units = 32, activation = "relu",
              kernel_regularizer = regularizer_l2(0.001)) %>%
  layer_dropout(rate = 0.2) %>%
  layer_dense(units = 1, activation = "sigmoid")

# model <- keras_model_sequential() %>%
#   layer_dense(units = 16, activation = "relu", input_shape = ncol(x_train)) %>%
#   layer_dropout(0.3) %>%
#   layer_dense(units = 1, activation = "sigmoid")


# Compile model
model %>% compile(
  optimizer = "adam",
  loss = "binary_crossentropy",
  metrics = c("accuracy")
)

# Fit model
history <- model %>% fit(
  x_train, y_train,
  epochs = 50,
  batch_size = 32,
  validation_data = list(x_valid, y_valid),
  callbacks = list(
    callback_early_stopping(patience = 5, restore_best_weights = TRUE)
  ),
  verbose = 1
)

```

```{r}
#| label: plot-history
#| eval: false
#| include: false
#| fig-cap: "Training vs Validation Accuracy"
plot(history)
```


```{r}
#| label: evaluate-test
#| eval: false
#| include: false
#| message: false
#| warning: false

# Evaluate on test data
model %>% evaluate(x_test, y_test)

```


```{r}
#| label: predictions-roc
#| eval: false
#| include: false
#| message: false
#| warning: false
#| fig-cap: "ROC Curve for Test Set"

# Predict probabilities
prob_pred <- model %>% predict(x_test)

# Binary classification threshold
class_pred <- ifelse(prob_pred > 0.5, 1, 0)

# Confusion matrix
table(Predicted = class_pred, Actual = y_test)

# ROC and AUC
roc_obj <- roc(y_test, prob_pred)
plot(roc_obj, col = "blue", print.auc = TRUE)

```

## DALEX for Feature Importance
```{r}
#| eval: false
#| include: false

library(DALEX)

# Wrap Keras model in a prediction function
predict_function <- function(model, newdata) {
  predict(model, as.matrix(newdata))
}

# Create DALEX explainer
explainer_nn <- explain(
  model = model,
  data = as.data.frame(x_test),
  y = y_test,
  predict_function = predict_function,
  label = "Neural Network"
)

# Plot feature importance (SHAP-like effect)
vip <- variable_importance(explainer_nn)


```

```{r}
#| eval: false
#| include: false

plot(vip, max_vars = 10)

```






## NOTES

- Fit NN, bigger one, show that the accuracy is worse than for previous methods
- Try to improve by feature engineering (var. filtering), changing structure, adding regularization
- Write conclusions why this is not performinng better than the trees
- Try adding embeddings from gene2vec


- Try Python version with embeddings (model from Hugging Face) instead

- Presentation: add slides about embeddings and SHAPELY


