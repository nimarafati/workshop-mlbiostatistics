---
title: "Neural Networks"
format:
  html:
    toc: true
    toc-location: right
    toc-depth: 5
    number-sections: false
    code-fold: false
    sidebar: true
    collapse-level: 4
editor: source
editor_options: 
  chunk_output_type: console
knitr:
  opts_chunk: 
    message: false
    warning: false
    code-fold: show
    include: true
    collapse: true
    eval: true
    fig.show: hold
---

# Introduction


## Load packages
```{r}
#| label: load-packages

# load packages
rm(list=ls())
library(tidyverse)
library(ggcorrplot)
library(glmnet)
library(fastDummies)
library(pROC)
library(class)
library(keras)
library(reticulate)


# Load the clinical data
data_obesity <- read_csv("data/data-obesity.csv") 

# Load gene expression data
data_expr <- read_csv("data/data-obesity-genes.csv")
genes_all <- colnames(data_expr)[-1]  # Exclude the 'id' column

# Genes
gens_known <- c("FTO", "MC4R", "LEP")
genes_other <- setdiff(genes_all, gens_known)

```


## Split Data

```{r}
#| label: split-data
#| eval: true
#| warning: false
#| message: false
#| code-fold: false

# join gene expression data with clinical data
data <- data_obesity %>%
  left_join(data_expr, by = "id") %>%
  dplyr::select("obese", all_of(genes_other)) %>%
  na.omit()

# select top 100 genes based on variance
# Calculate variance for each gene
gene_vars <- data %>%
  select(-obese) %>%
  summarise(across(everything(), var)) %>%
  pivot_longer(everything(), names_to = "gene", values_to = "variance")

# Select top 100 most variable genes
top_genes <- gene_vars %>%
  arrange(desc(variance)) %>%
  slice_head(n = 100) %>%
  pull(gene)

# Subset the data to use only top 100 genes
data <- data %>%
  select(obese, all_of(top_genes))


# three-way split: train (60%), validation (20%), test (20%)
set.seed(123)
n <- nrow(data)
idx <- sample(seq_len(n))
idx_train <- idx[1:floor(0.6 * n)]
idx_valid <- idx[(floor(0.6 * n) + 1):floor(0.8 * n)]
idx_test  <- idx[(floor(0.8 * n) + 1):n]

data_train <- data[idx_train, ]
data_valid <- data[idx_valid, ]
data_test  <- data[idx_test, ]

# To keep focus on the important parts, we will skip feature engineering
# and we will just scale all data
x_train <- data_train %>%
  dplyr::select(-obese) %>%
  as.matrix() %>%
  scale()

x_valid <- data_valid %>%
  dplyr::select(-obese) %>%
  as.matrix() %>%
  scale()

x_test <- data_test %>%
  dplyr::select(-obese) %>%
  as.matrix() %>%
  scale()

# Separate and format target variable
y_train <- data_train$obese
y_train <- ifelse(y_train == "Yes", 1, 0) 

y_valid <- data_valid$obese
y_valid <- ifelse(y_valid == "Yes", 1, 0)

y_test <- data_test$obese
y_test <- ifelse(y_test == "Yes", 1, 0)

```

## K

```{r}
#| label: keras-model
#| eval: true
#| message: false
#| warning: false

# Define model
# model <- keras_model_sequential() %>%
#   layer_dense(units = 64, activation = "relu", input_shape = ncol(x_train)) %>%
#   layer_dropout(0.3) %>%
#   layer_dense(units = 32, activation = "relu") %>%
#   layer_dropout(0.2) %>%
#   layer_dense(units = 1, activation = "sigmoid")


# Define model with L2 regularization
model <- keras_model_sequential() %>%
  layer_dense(units = 64, activation = "relu", input_shape = ncol(x_train),
              kernel_regularizer = regularizer_l2(0.001)) %>%
  layer_dropout(rate = 0.3) %>%
  layer_dense(units = 32, activation = "relu",
              kernel_regularizer = regularizer_l2(0.001)) %>%
  layer_dropout(rate = 0.2) %>%
  layer_dense(units = 1, activation = "sigmoid")

# model <- keras_model_sequential() %>%
#   layer_dense(units = 16, activation = "relu", input_shape = ncol(x_train)) %>%
#   layer_dropout(0.3) %>%
#   layer_dense(units = 1, activation = "sigmoid")


# Compile model
model %>% compile(
  optimizer = "adam",
  loss = "binary_crossentropy",
  metrics = c("accuracy")
)

# Fit model
history <- model %>% fit(
  x_train, y_train,
  epochs = 50,
  batch_size = 32,
  validation_data = list(x_valid, y_valid),
  callbacks = list(
    callback_early_stopping(patience = 5, restore_best_weights = TRUE)
  ),
  verbose = 1
)

```

```{r}
#| label: plot-history
#| fig-cap: "Training vs Validation Accuracy"
plot(history)
```


```{r}
#| label: evaluate-test
#| message: false
#| warning: false

# Evaluate on test data
model %>% evaluate(x_test, y_test)

```


```{r}
#| label: predictions-roc
#| message: false
#| warning: false
#| fig-cap: "ROC Curve for Test Set"

# Predict probabilities
prob_pred <- model %>% predict(x_test)

# Binary classification threshold
class_pred <- ifelse(prob_pred > 0.5, 1, 0)

# Confusion matrix
table(Predicted = class_pred, Actual = y_test)

# ROC and AUC
roc_obj <- roc(y_test, prob_pred)
plot(roc_obj, col = "blue", print.auc = TRUE)

```

## DALEX for Feature Importance
```{r}
library(DALEX)

# Wrap Keras model in a prediction function
predict_function <- function(model, newdata) {
  predict(model, as.matrix(newdata))
}

# Create DALEX explainer
explainer_nn <- explain(
  model = model,
  data = as.data.frame(x_test),
  y = y_test,
  predict_function = predict_function,
  label = "Neural Network"
)

# Plot feature importance (SHAP-like effect)
vip <- variable_importance(explainer_nn)


```

```{r}
plot(vip, max_vars = 10)


```






## NOTES

- Fit NN, bigger one, show that the accuracy is worse than for previous methods
- Try to improve by feature engineering (var. filtering), changing structure, adding regularization
- Write conclusions why this is not performinng better than the trees
- Try adding embeddings from gene2vec


- Try Python version with embeddings (model from Hugging Face) instead

- Presentation: add slides about embeddings and SHAPELY


