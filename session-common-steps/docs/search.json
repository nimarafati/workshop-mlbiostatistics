[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Common steps",
    "section": "",
    "text": "Preface\nThis tutorial is intended as a refresher of the common data analysis steps, such as exploratory data analysis, statistical testing, as well as building and evaluating predictive models.\nLearning outcomes\n\nPerform exploratory data analysis (EDA) to summarize, visualize, and interpret trends in clinical and gene expression data.\nIdentify and handle missing data appropriately, using basic imputation strategies where needed.\nConduct association tests (e.g., logistic regression with multiple testing correction) to identify genes linked to obesity status.\nApply Principal Component Analysis (PCA) to explore the structure of high-dimensional gene expression data and detect patterns such as clustering or outliers.\nFit and interpret logistic regression models using both clinical variables and high-dimensional molecular predictors.\nUnderstand and apply Lasso regularization to perform variable selection and reduce model complexity in the presence of many predictors.\nInterpret key model evaluation metrics, including accuracy, precision, recall, F1 score, and AUC.\nFit and evaluate Random Forest models for classification tasks, and interpret variable importance.\nTune Random Forest hyperparameters using grid search to optimize model performance.\nCompare different modeling approaches (logistic regression, Lasso, Random Forest) in terms of both predictive accuracy and interpretability in the context of biomedical data.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "case-study-base-r-cls.html",
    "href": "case-study-base-r-cls.html",
    "title": "Common steps",
    "section": "",
    "text": "A case study: understanding obesity\nLet’s go through a case study to illustrate the common steps in a life science data analysis project. We will use clinical data based on the diabetes study from the faraway package, along with additional simulated gene expression data related to obesity.\nOur goal is to better understand obesity, particularly whether there are any genes associated with obesity status (“Yes”).\nThis tutorial serves as a refresher on key concepts from our foundation course, Introduction to Biostatistics and Machine Learning. Please make sure you follow and understand each step, as we will build on these methods throughout the week.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Common steps</span>"
    ]
  },
  {
    "objectID": "case-study-base-r-cls.html#load-packages",
    "href": "case-study-base-r-cls.html#load-packages",
    "title": "Common steps",
    "section": "Load packages",
    "text": "Load packages\n\n# load packages\nrm(list=ls())\nlibrary(tidyverse)\nlibrary(ggcorrplot)\nlibrary(glmnet) # for fitting GLMs\nlibrary(fastDummies) # for features processing\nlibrary(pROC)      # for ROC curves and AUC\nlibrary(ranger) # for random forest",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Common steps</span>"
    ]
  },
  {
    "objectID": "case-study-base-r-cls.html#load-data",
    "href": "case-study-base-r-cls.html#load-data",
    "title": "Common steps",
    "section": "Load Data",
    "text": "Load Data\n\n# Load the clinical data\ndata_obesity &lt;- read_csv(\"data/data-obesity.csv\") \n\n# Load gene expression data\ndata_expr &lt;- read_csv(\"data/data-obesity-genes.csv\")\n\n# preview clinical data\ndim(data_obesity)\n## [1] 403  21\nglimpse(data_obesity)\n## Rows: 403\n## Columns: 21\n## $ id       &lt;dbl&gt; 1000, 1001, 1002, 1003, 1005, 1008, 1011, 1015, 1016, 1022, 1…\n## $ BMI      &lt;dbl&gt; 22.13, 37.42, 48.37, 18.64, 27.82, 26.50, 28.20, 34.33, 24.51…\n## $ obese    &lt;chr&gt; \"No\", \"Yes\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"Yes…\n## $ chol     &lt;dbl&gt; 203, 165, 228, 78, 249, 248, 195, 227, 177, 263, 242, 215, 23…\n## $ stab.glu &lt;dbl&gt; 82, 97, 92, 93, 90, 94, 92, 75, 87, 89, 82, 128, 75, 79, 76, …\n## $ hdl      &lt;dbl&gt; 56, 24, 37, 12, 28, 69, 41, 44, 49, 40, 54, 34, 36, 46, 30, 4…\n## $ ratio    &lt;dbl&gt; 3.6, 6.9, 6.2, 6.5, 8.9, 3.6, 4.8, 5.2, 3.6, 6.6, 4.5, 6.3, 6…\n## $ glyhb    &lt;dbl&gt; 4.31, 4.44, 4.64, 4.63, 7.72, 4.81, 4.84, 3.94, 4.84, 5.78, 4…\n## $ location &lt;chr&gt; \"Buckingham\", \"Buckingham\", \"Buckingham\", \"Buckingham\", \"Buck…\n## $ age      &lt;dbl&gt; 46, 29, 58, 67, 64, 34, 30, 37, 45, 55, 60, 38, 27, 40, 36, 3…\n## $ gender   &lt;chr&gt; \"female\", \"female\", \"female\", \"male\", \"male\", \"male\", \"male\",…\n## $ height   &lt;dbl&gt; 62, 64, 61, 67, 68, 71, 69, 59, 69, 63, 65, 58, 60, 59, 69, 6…\n## $ weight   &lt;dbl&gt; 121, 218, 256, 119, 183, 190, 191, 170, 166, 202, 156, 195, 1…\n## $ frame    &lt;chr&gt; \"medium\", \"large\", \"large\", \"large\", \"medium\", \"large\", \"medi…\n## $ bp.1s    &lt;dbl&gt; 118, 112, 190, 110, 138, 132, 161, NA, 160, 108, 130, 102, 13…\n## $ bp.1d    &lt;dbl&gt; 59, 68, 92, 50, 80, 86, 112, NA, 80, 72, 90, 68, 80, NA, 66, …\n## $ bp.2s    &lt;dbl&gt; NA, NA, 185, NA, NA, NA, 161, NA, 128, NA, 130, NA, NA, NA, N…\n## $ bp.2d    &lt;dbl&gt; NA, NA, 92, NA, NA, NA, 112, NA, 86, NA, 90, NA, NA, NA, NA, …\n## $ waist    &lt;dbl&gt; 29, 46, 49, 33, 44, 36, 46, 34, 34, 45, 39, 42, 35, 37, 36, 3…\n## $ hip      &lt;dbl&gt; 38, 48, 57, 38, 41, 42, 49, 39, 40, 50, 45, 50, 41, 43, 40, 4…\n## $ time.ppn &lt;dbl&gt; 720, 360, 180, 480, 300, 195, 720, 1020, 300, 240, 300, 90, 7…\n\n# From the glimpse output\n# - we can see that we have a mixture of numerical and categorical variables\n# - and we note that we have missing data, NAs\n\n# Check how many in each group\ntable(data_obesity$obese)\n## \n##  No Yes \n## 243 154\n\n# Exclude BMI and hip variables (we will not need them for this analysis)\n# since both BMI and hip are closely related to obesity status\ndata_obesity &lt;- data_obesity %&gt;%\n  select(-BMI, -hip)\n\n# preview gene expression data\nprint(dim(data_expr))\n## [1]  403 1001\nprint(data_expr[1:5, 1:5])\n## # A tibble: 5 × 5\n##      id    AFF3 `RNU6-890P` ZYG11A `SNORD115-36`\n##   &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;\n## 1  1000 -0.318       -0.330 -0.801         0.614\n## 2  1001  1.25         1.17   0.422         0.517\n## 3  1002 -0.399       -0.465  0.194         1.17 \n## 4  1003  0.813       -1.01   1.54         -0.314\n## 5  1005  0.0804       0.737 -0.567        -1.95",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Common steps</span>"
    ]
  },
  {
    "objectID": "case-study-base-r-cls.html#perform-eda",
    "href": "case-study-base-r-cls.html#perform-eda",
    "title": "Common steps",
    "section": "Perform EDA",
    "text": "Perform EDA\n\n# run basic EDA\n# - let's look at the distribution of numerical variables\n# - missing data\n# - and correlation between clinical variables\n\ndata_obesity %&gt;%\n  select(\"obese\", where(is.numeric), -id) %&gt;% \n  pivot_longer(-obese, names_to = \"variable\", values_to = \"value\") %&gt;% \n  ggplot(aes(x = value)) +\n  geom_histogram(bins = 30, fill = \"blue4\", color = \"white\") +\n  facet_wrap(~ variable, scales = \"free\") +\n  theme_bw() +\n  labs(title = \"Distribution of Numerical Variables\") + \n  ylab(\"\")\n\n# stratify by obesity status (Yes/No)\ndata_obesity %&gt;%\n  select(\"obese\", where(is.numeric), -id) %&gt;% \n  pivot_longer(-obese, names_to = \"variable\", values_to = \"value\") %&gt;% \n  ggplot(aes(x = value, fill = obese)) +\n  geom_histogram(bins = 30, color = \"white\", position = \"identity\", alpha = 0.5) +\n  facet_wrap(~ variable, scales = \"free\") +\n  theme_bw() +\n  labs(title = \"Distribution of Numerical Variables by Obesity Status\") + \n  ylab(\"\") + \n  scale_fill_manual(values = c(\"No\" = \"blue4\", \"Yes\" = \"red4\")) \n\n# summarize categorical variables by obesity status\ndata_obesity %&gt;%\n  select(\"obese\", where(is.character), -id) %&gt;%\n  pivot_longer(-obese, names_to = \"variable\", values_to = \"value\") %&gt;%\n  group_by(variable, value, obese) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  ggplot(aes(x = value, y = count, fill = obese)) +\n  geom_col(position = \"dodge\") +\n  facet_wrap(~ variable, scales = \"free\") +\n  theme_bw() +\n  labs(title = \"Counts of Categorical Variables by Obesity Status\") +\n  ylab(\"\") +\n  scale_fill_manual(values = c(\"No\" = \"blue4\", \"Yes\" = \"red4\"))\n\n# distribution of randomly selected 10 genes\ndata_expr %&gt;%\n  select(id, sample(2:ncol(data_expr), 12)) %&gt;%\n  pivot_longer(-id, names_to = \"gene\", values_to = \"expression\") %&gt;%\n  ggplot(aes(x = expression)) +\n  geom_histogram(bins = 30, fill = \"blue4\", color = \"white\") +\n  facet_wrap(~ gene, scales = \"free\") +\n  theme_bw() +\n  labs(title = \"Distribution of Randomly Selected Genes\") + \n  xlab(\"\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# calculate number of missing data per variable\ndata_na &lt;- data_obesity %&gt;% \n  summarise(across(everything(), ~ sum(is.na(.)))) \n\n# make a table with counts sorted from highest to lowest\ndata_na_long &lt;- data_na %&gt;%\n  pivot_longer(-id, names_to = \"variable\", values_to = \"count\") %&gt;%\n  arrange(desc(count)) \n\n# make a column plot to visualize the counts\ndata_na_long %&gt;%\n  ggplot(aes(x = variable, y = count)) + \n  geom_col(fill = \"blue4\") + \n  xlab(\"\") + \n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))\n\n# Based on the number of missing data, let's delete bp.2s, bp.2d\n# and use complete-cases analysis \ndata_obesity &lt;- data_obesity %&gt;%\n  dplyr::select(-bp.2s, -bp.2d) %&gt;%\n  na.omit()\n\n\n\n\nNumber of missing data per variable, shows that bp.2d and bp.2s have more than 50% missing entries\n\n\n\n\n\n# Correlation heatmap\ndata_cor &lt;- data_obesity %&gt;%\n  select(where(is.numeric), -id) %&gt;%\n  cor()\n\nggcorrplot(data_cor, hc.order = TRUE, lab = FALSE)\n\n\n\n\nHeatmap visualizing Pearson correlation coefficient between numerical variables\n\n\n\n\n\nTask I: PCA\nWrite your own code to perform PCA on the gene expression data.\n\nMake a scores plot and color by obesity status. Would you say that the groups separate well?\nWhich genes contribute the most to the first principal component (PC1)?\n\n\n\nExample code\n# Perform PCA on gene expression data\n\n# filter gene expression data to include only those with obesity status\nx &lt;- data_expr %&gt;%\n  filter(id %in% data_obesity$id) %&gt;%\n  column_to_rownames(\"id\") %&gt;%\n  as.matrix()\n\n# Scale the data prior pca\nx_scaled &lt;- scale(x)\n\n# Calculate PCA\npca &lt;- prcomp(x, center=TRUE, scale.=FALSE)\neigs &lt;- pca$sdev^2\nvar_exp &lt;- eigs / sum(eigs)\n\nres_pca &lt;- data.frame(PC1=pca$x[,1], PC2=pca$x[,2], PC3=pca$x[,3], PC4=pca$x[,4], PC5=pca$x[,5]) |&gt;\n    rownames_to_column(\"id\") |&gt; \n    mutate(id = as.integer(id)) |&gt;\n    as_tibble() |&gt; \n    left_join(data_obesity, by=\"id\")\n\nres_pca_loadings &lt;- pca$rotation\n\n# show PCA scores plot\nres_pca |&gt;\n    ggplot(aes(x=PC1, y=PC2, group = obese, fill = obese)) +\n    geom_point(alpha = 0.6,  shape = 21, size = 2) +\n    labs(title=\"PCA scores plot\", x=\"PC1\", y=\"PC2\") +\n    xlab(paste(\"PC1 (Var: \", round(var_exp[1] * 100, 2), \"%)\")) +\n    ylab(paste(\"PC2 (Var: \", round(var_exp[2] * 100, 2), \"%)\")) +\n    theme_minimal() +\n    theme(legend.title=element_blank()) + \n  scale_fill_manual(values = c(\"No\" = \"blue4\", \"Yes\" = \"red4\")) \n\n# show top 10 loadings along PC1\nres_pca_loadings |&gt; \n    as.data.frame() |&gt; \n    rownames_to_column(\"gene\") |&gt; \n    arrange(desc(abs(PC1))) |&gt; \n    head(10) |&gt; \n    ggplot(aes(x=reorder(gene, PC1), y=PC1)) +\n    geom_bar(stat=\"identity\", fill=\"steelblue\") +\n    coord_flip() +\n    labs(title=\"Top genes contributing to PC1\", x=\"gene\", y=\"Loading\") +\n    theme_minimal()\n\n# Answers: \n# 1. The groups separate moderately well, with some overlap, along PC1\n# 2. The top genes contributing to PC1 can be found in the loadings plot, top three are POMC, PCSK1 and MC4R",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Common steps</span>"
    ]
  },
  {
    "objectID": "case-study-base-r-cls.html#associations-logistic-regression",
    "href": "case-study-base-r-cls.html#associations-logistic-regression",
    "title": "Common steps",
    "section": "Associations: logistic regression",
    "text": "Associations: logistic regression\nFrom the previous studies we may know a gene or two that are associated with obesity status. Let’s check if FTO is associated with obesity status in our data, controlling for age and height.\n\n# Combine data: assume gene_df contains only genes, and meta_df contains metadata\ndata &lt;- data_obesity %&gt;%\n  left_join(data_expr, by = \"id\") \n\n# Make sure obesity status is coded as binary (0 = No, 1 = Yes)\ndata &lt;- data %&gt;%\n  mutate(obese = as.factor(obese)) %&gt;%\n  mutate(gender = as.factor(gender))\n\n# Fit logistic regression\ngene &lt;- \"FTO\"  # Example gene to test\nformula_str &lt;- paste(\"obese ~\", paste0(\"`\", gene, \"`\"), \"+ age + height + gender\")\nmodel &lt;- glm(as.formula(formula_str), data = data, family = \"binomial\")\nprint(summary(model))  \n## \n## Call:\n## glm(formula = as.formula(formula_str), family = \"binomial\", data = data)\n## \n## Coefficients:\n##              Estimate Std. Error z value Pr(&gt;|z|)    \n## (Intercept)  0.233900   3.027166   0.077   0.9384    \n## FTO          1.200349   0.145673   8.240   &lt;2e-16 ***\n## age          0.006252   0.008174   0.765   0.4443    \n## height      -0.018877   0.046052  -0.410   0.6819    \n## gendermale  -0.779551   0.359679  -2.167   0.0302 *  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 489.76  on 365  degrees of freedom\n## Residual deviance: 375.61  on 361  degrees of freedom\n## AIC: 385.61\n## \n## Number of Fisher Scoring iterations: 4\n\n# From the output we see that\n# - FTO is significantly associated with obesity status (p &lt; 0.05)\n# - The FTO estimate (log-odds) is 1.2 corresponding to an odds ratio of exp(1.2) = 3.32.\n# - For every 1-unit increase in FTO expression, the odds of being obese increase by a factor of approximately 3.32, assuming all other variables are held constant.\n# - There is also a gender effect, with exp(-0.78) = 0.46\n# - meaning that the odds of being obese for males are 0.46 times the odds for females, \n# - or in other words: Holding all other variables constant, males have 54% lower odds of being obese compared to females.\n\n\nTask II: Associations\nAre there any other genes associated with obesity status?\n\nWrite your own code to fit logistic regression models, including age, height and gender as covariates (known confounders from prior studies).\nAdjust your p-values for multiple testing using the Benjamini-Hochberg method.\n\n\nWhat are the top 5 genes associated with obesity status after FDR adjustment?\nHow many genes show statistically significant association with obesity status at a false discovery rate (FDR) threshold of 0.05?\n\n\n\nExample code\n# Store logistic model outputs\nall_genes &lt;- colnames(data_expr)[-1]  # Exclude 'id' column, all gene names\nn_genes &lt;- length(all_genes)  # no of genes\nestimate &lt;- std_error &lt;- z_value &lt;- pvals &lt;- numeric(n_genes) # initialize vectors for estimates, standard errors, z-values and p-values\n\n# Loop over genes to fit logistic regression: obese ~ gene + age + height + gender\ni &lt;- 1\nfor (gene in all_genes) {\n  \n  formula_str &lt;- paste(\"obese ~\", paste0(\"`\", gene, \"`\"), \"+ age + height + gender\")\n  model &lt;- glm(as.formula(formula_str), data = data, family = \"binomial\")\n\n  estiamte[i] &lt;- coef(summary(model))[2,1 ]  # coefficient for the gene\n  std_error[i] &lt;- coef(summary(model))[2, 2]  # standard error for the gene\n  z_value[i] &lt;- coef(summary(model))[2, 3]  # z-value for the gene\n  pvals[i] &lt;- coef(summary(model))[2, 4] # p-value for the gene\n  \n  i &lt;- i + 1\n}\n\n# Adjust p-values using Benjamini-Hochberg (FDR)\np_adj &lt;- p.adjust(pvals, method = \"BH\")\n\n# Create result data frame\nresults_df &lt;- data.frame(\n  gene = all_genes,\n  estimate = estimate,\n  std_error = std_error,\n  z_value = z_value,\n  p_value = gene_pvals,\n  p_adj = p_adj\n)\n\n# View top hits\nhead(results_df[order(results_df$p_adj), ], n = 10)\n\n# Number of significant genes after FDR adjustment\nsignificant_genes &lt;- sum(results_df$p_adj &lt; 0.05)\ncat(\"Number of significant genes after FDR adjustment:\", significant_genes, \"\\n\")",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Common steps</span>"
    ]
  },
  {
    "objectID": "case-study-base-r-cls.html#predictive-models",
    "href": "case-study-base-r-cls.html#predictive-models",
    "title": "Common steps",
    "section": "Predictive models",
    "text": "Predictive models\nIf instead of testing for associations we want to build a predictive model to predict obesity status based on gene expression data, we could use machine learning methods such as Lasso regression or Random Forest. Let’s do just that, and see which method will results in a better prediction performance.\n\nSplit Data\n\n# join gene expression data with clinical data\ndata &lt;- data_obesity %&gt;%\n  left_join(data_expr, by = \"id\")\n\n# split data into train and test\nset.seed(123)\nn &lt;- nrow(data)\ntest_index &lt;- sample(seq_len(n), size = 0.2 * n)\ndata_test &lt;- data[test_index, ]\ndata_train &lt;- data[-test_index, ]\n\n\n\nFeature Engineering and Scaling\n\n# Conversion factors\ninch2m &lt;- 2.54 / 100\npound2kg &lt;- 0.45\n\n# ---- Process Training Data ----\ndata_train_processed &lt;- data_train %&gt;%\n  mutate(\n    height = round(height * inch2m, 2),\n    weight = round(weight * pound2kg, 2),\n    glu = log(stab.glu)\n  ) %&gt;%\n  select(-stab.glu, -id)\n\n# Remove zero-variance features\nnzv &lt;- sapply(data_train_processed, function(x) length(unique(x)) &gt; 1)\ndata_train_processed &lt;- data_train_processed[, nzv]\n\n# Remove highly correlated predictors (|r| &gt; 0.8)\ncor_matrix &lt;- cor(select(data_train_processed, where(is.numeric)))\nhigh_corr &lt;- names(which(apply(cor_matrix, 2, function(x) any(abs(x) &gt; 0.8 & abs(x) &lt; 1))))\n\n#data_train_processed &lt;- data_train_processed %&gt;% select(-all_of(high_corr))\ndata_train_processed &lt;- data_train_processed %&gt;% select(-c(\"weight\", \"waist\"))\n\n# Dummy encode categorical variables\ndata_train_processed &lt;- dummy_cols(data_train_processed,\n                                   select_columns = c(\"location\", \"gender\", \"frame\"),\n                                   remove_selected_columns = TRUE)\n\n# Separate outcome and predictors\ny_train &lt;- data_train_processed$obese\nx_train &lt;- data_train_processed %&gt;% select(-obese)\n\n# Scale predictors\nx_train_scaled &lt;- scale(x_train)\ntrain_means &lt;- attr(x_train_scaled, \"scaled:center\")\ntrain_sds &lt;- attr(x_train_scaled, \"scaled:scale\")\n\n\n\nPrepare Test Data with Same Processing\n\n# ---- Process Test Data ----\ndata_test_processed &lt;- data_test %&gt;%\n  mutate(\n    height = round(height * inch2m, 2),\n    weight = round(weight * pound2kg, 2),\n    glu = log(stab.glu)\n  ) %&gt;%\n  select(-stab.glu, -id)\n\n# Dummy encode categorical variables\ndata_test_processed &lt;- dummy_cols(data_test_processed,\n                                  select_columns = c(\"location\", \"gender\", \"frame\"),\n                                  remove_selected_columns = TRUE)\n\n# Remove same columns as in training\ndata_test_processed &lt;- data_test_processed %&gt;%\n  select(colnames(data_train_processed))\n\n# Ensure same column order as training\nx_test &lt;- data_test_processed %&gt;% select(-obese)\nx_test &lt;- x_test[, colnames(x_train)]\n\n# Apply training set scaling\nx_test_scaled &lt;- scale(x_test, center = train_means, scale = train_sds)\ny_test &lt;- data_test_processed$obese\n\n\n\nLasso Regression with Cross-Validation\nAs a reminder, Lasso logistic regression is a form of penalized logistic regression that incorporates L1 regularization to prevent overfitting and perform automatic variable selection.\nIn standard logistic regression, we model the log-odds of a binary outcome as a linear combination of predictors. However, when the number of predictors is large, or when predictors are correlated, the model can become unstable or overfit.\nTo address this, Lasso (Least Absolute Shrinkage and Selection Operator) adds a penalty term to the likelihood function and we minimize the following loss function:\n\\[ \\text{Minimize: } \\text{RSS} + \\lambda \\sum_{j=1}^{p}|\\beta_j|\\]\n\nThe log-likelihood measures how well the model fits the data.\nThe L1 penalty shrinks some coefficients exactly to zero, effectively selecting a subset of predictors.\nThe tuning parameter λ (lambda) controls the strength of regularization:\n\nWhen λ = 0 → standard logistic regression\nAs λ increases → more coefficients shrink to zero\n\n\nLasso automatically excludes irrelevant predictors and results in a spare model, easy to interpret.\n\n# Fit Lasso regression with 10-fold CV\nset.seed(123)\ncv_model &lt;- cv.glmnet(x_train_scaled, y_train, alpha = 1, standardize = FALSE, family = \"binomial\")\n\n# Plot cross-validation error\nplot(cv_model)\n\n# Best lambda value\nbest_lambda &lt;- cv_model$lambda.1se\ncat(\"Best lambda:\", best_lambda)\n## Best lambda: 0.05232717\n\n\n\n\n\n\n\n\n\n\nEvaluate Model on Test Data\n\n# Predict obesity status give the test data\npred_test &lt;- predict(cv_model, s = best_lambda, newx = x_test_scaled, type = \"response\")\nprint(head(pred_test))\n##              s1\n## [1,] 0.55987925\n## [2,] 0.05089643\n## [3,] 0.15378199\n## [4,] 0.63425972\n## [5,] 0.16356896\n## [6,] 0.57418592\ny_pred &lt;- ifelse(pred_test &gt; 0.5, \"Yes\", \"No\")\n\n# Predictions (from earlier)\npred_probs &lt;- predict(cv_model, newx = x_test_scaled, s = best_lambda, type = \"response\")\npred_labels &lt;- ifelse(pred_probs &gt;= 0.5, 1, 0)\n\n# confusion matrix\nconf_matrix &lt;- table(Predicted = y_pred, Actual = y_test)\nprint(conf_matrix)\n##          Actual\n## Predicted No Yes\n##       No  40   2\n##       Yes  7  24\n\n# accuracy\naccuracy &lt;- sum(diag(conf_matrix)) / sum(conf_matrix)\ncat(\"Accuracy:\", round(accuracy, 3), \"\\n\")\n## Accuracy: 0.877\n\n# compute precision, recall, F1 \nTP &lt;- conf_matrix[\"Yes\", \"Yes\"]\nFP &lt;- conf_matrix[\"Yes\", \"No\"]\nFN &lt;- conf_matrix[\"No\", \"Yes\"]\n\nprecision &lt;- TP / (TP + FP)\nrecall    &lt;- TP / (TP + FN)\nf1_score  &lt;- 2 * (precision * recall) / (precision + recall)\n\ncat(\"Precision:\", round(precision, 3), \"\\n\")\n## Precision: 0.774\ncat(\"Recall:\", round(recall, 3), \"\\n\")\n## Recall: 0.923\ncat(\"F1 Score:\", round(f1_score, 3), \"\\n\")\n## F1 Score: 0.842\n\n# ROC Curve and AUC\ny_test_numeric &lt;- ifelse(y_test == \"Yes\", 1, 0)  # Convert to numeric for ROC\ny_pred_numeric &lt;- as.numeric(ifelse(y_pred == \"Yes\", 1, 0))  # Convert to numeric for ROC\n\nroc_obj &lt;- roc(y_test_numeric, as.numeric(pred_probs))\nplot(roc_obj, main = \"ROC Curve\", col = \"blue\", lwd = 2)\nabline(a = 0, b = 1, lty = 2, col = \"gray\")\n\nauc_val &lt;- auc(roc_obj)\ncat(\"AUC:\", round(auc_val, 3), \"\\n\")\n## AUC: 0.966\n\n\n\n\n\n\n\n\n\n\nVariable Importance Plot\n\n# Extract coefficients\ncoef_matrix &lt;- coef(cv_model, s = best_lambda)\ncoef_df &lt;- as.data.frame(as.matrix(coef_matrix))\ncoef_df$feature &lt;- rownames(coef_df)\ncolnames(coef_df)[1] &lt;- \"coefficient\"\n\n# Filter out intercept and zero coefficients\ncoef_df &lt;- coef_df %&gt;%\n  filter(feature != \"(Intercept)\", coefficient != 0) %&gt;%\n  mutate(abs_coef = abs(coefficient)) %&gt;%\n  arrange(desc(abs_coef))\n\n# Plot\nggplot(coef_df, aes(x = reorder(feature, abs_coef), y = abs_coef)) +\n  geom_col(fill = \"steelblue\") +\n  coord_flip() +\n  labs(title = \"Variable Importance (Lasso Coefficients)\",\n       x = \"Feature\", y = \"Absolute Coefficient\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThe Lasso logistic regression model achieved an accuracy of 87.7% and a high AUC of 0.966, indicating excellent overall discrimination between obese and non-obese individuals. With a precision of 0.774 and recall of 0.923, the model performs especially well at identifying obese individuals, while maintaining a relatively low false positive rate.\nThe Variable Importance plot shows that several well-known obesity-related genes such as POMC, FTO, LEP, PCSK1, LEPR, and MC4R were selected by the Lasso model as important predictors of obesity status, based on the magnitude of their coefficients. The largest coefficients were observed for POMC and FTO, suggesting these genes contributed most strongly to the model’s classification of obesity. Additionally, a few clinical features like frame size and height were retained, though with smaller effects, while LINC01144, a non-coding RNA, had only a minimal contribution.\n\n\nRandom Forest\nA decision tree is a simple, rule-based model used for classification or regression.\n\nIt splits the data into branches based on predictor variables.\nEach split is chosen to maximize separation between outcomes (e.g., using Gini impurity or information gain for classification).\nThe tree continues splitting until a stopping rule is met (e.g., minimum node size or depth).\n\nA tree predicting obesity status might learn rules like:\n\nIf FTO expression &gt; 1.5 → predict “obese”\nElse if height &lt; 165 cm → predict “not obese”\n\nDecisions tree are easy to interpret, handles both numerical and categorical data and aptures non-linear relationships. However, a single tree is unstable and often overfit the training data.\nA Random Forest solves the overfitting problem by building an ensemble of many decision trees, each trained slightly differently.\nThe “forest” part:\n\nIt trains hundreds of decision trees.\nEach tree makes its own prediction.\nThe forest combines these:\n\nFor classification: majority vote\nFor regression: average of predictions\n\n\nThe “random” part:\nRandomness is introduced in two ways to make each tree different:\n\nBootstrap sampling: each tree is trained on a random sample (with replacement) of the data.\nRandom feature selection: At each split, the tree considers a random subset of predictors, not all of them.\n\nThese random elements help diversify the trees, reduce overfitting, and improve generalization.\nRandom Forests are widely used in life sciences for tasks like gene classification, patient stratification, and biomarker discovery, as they can handle many predictors and complex interactions and provide variable importance scores, great for feature selection.\n\n# Let's train Random Forest model with ranger() package\n\n# Combine predictors and target into a single data frame for ranger\ntrain_df &lt;- data.frame(y = factor(y_train), x_train_scaled)\n\n# Fit the random forest model using default parameters\nset.seed(123)\nrf_model &lt;- ranger(\n  formula = y ~ ., \n  data = train_df,\n  probability = TRUE,         # Enable probability predictions for ROC\n  num.trees = 500,\n  importance = \"impurity\"\n)\n\n\n# Evaluate the Random Forest model on the test set\n\n# Create test data frame with same structure\ntest_df &lt;- data.frame(x_test_scaled)\n\n# Predict probabilities for the positive class\nrf_probs &lt;- predict(rf_model, data = test_df)$predictions[, \"Yes\"]\n\n# Binary predictions using threshold\nrf_preds &lt;- ifelse(rf_probs &gt;= 0.5, \"Yes\", \"No\")\n\n# Confusion matrix (base R)\nconf_matrix &lt;- table(Predicted = rf_preds, Actual = y_test)\nprint(conf_matrix)\n##          Actual\n## Predicted No Yes\n##       No  46  19\n##       Yes  1   7\n\n# Accuracy\naccuracy &lt;- sum(diag(conf_matrix)) / sum(conf_matrix)\ncat(\"Accuracy:\", round(accuracy, 3), \"\\n\")\n## Accuracy: 0.726\n\n# ROC and AUC\nroc_obj &lt;- roc(y_test, rf_probs)\nplot(roc_obj, col = \"blue\", lwd = 2, main = \"Random Forest ROC\")\nabline(a = 0, b = 1, lty = 2, col = \"gray\")\ncat(\"AUC:\", auc(roc_obj), \"\\n\")\n## AUC: 0.8715221\n\n\n\n\n\n\n\n\n\n# feature importance\nimportance &lt;- rf_model$variable.importance\n\n# Convert to data frame\nimportance_df &lt;- data.frame(\n  feature = names(importance),\n  importance = importance\n)\n\n# Plot top features\nimportance_df &lt;- importance_df %&gt;%\n  arrange(desc(importance))\n\nggplot(importance_df[1:20, ], aes(x = reorder(feature, importance), y = importance)) +\n  geom_col(fill = \"darkgreen\") +\n  coord_flip() +\n  labs(\n    title = \"Variable Importance (Random Forest)\",\n    x = \"Feature\", y = \"Importance (Gini Impurity)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThe Random Forest model achieved an accuracy of 72.6% and an AUC of 0.87, which is notably lower than the Lasso model’s accuracy (87.7%) and AUC (0.97). While RF achieved a very low false positive rate (only 1 false positive), it struggled to correctly identify obese individuals, with only 7 true positives and 19 false negatives, indicating low recall.\nThe Random Forest model highlights POMC, PCSK1, FTO, LEP, MC4R, and LEPR as the top features contributing to classification accuracy, consistent with the Lasso model, where the same genes were also selected with large coefficients, suggesting strong and reproducible signals across methods. However, it does not identify height nor frame size as important features, which were retained in the Lasso model, instead it is reporting hdl.\nWe have however only run Random Forest with default parameters, and it is most likely it is not optimally tuned for this dataset. Random Forests are powerful but can be sensitive to hyperparameters, such as the number of trees, the number of features considered at each split (mtry), and the minimum size of terminal nodes (min.node.size).\n\n\nTask III: tune Random Forsest\nTo improve the Random Forest model’s performance, tune its hyperparameters using a grid search approach. Specifically, experiment with mtry (the number of predictors randomly selected at each split) and min.node.size (the minimum number of observations required in a terminal node) and record the AUC for each combination.\nTo keep it simple, you can try the below values of mtry and min.node.size\n\nmtry = c(5, 10, 20, 50),\nmin.node.size = c(1, 5, 10)\n\nAfter finding the best combination of hyperparameters, compare the tuned Random Forest model’s performance to the default Random Forest model and the Lasso model.\n\nWhich combination of mtry and min.node.size resulted in the highest AUC?\nHow does the tuned model’s performance compare to the default Random Forest model? How does it compare to the Lasso model?\n\n\n\nExample code\n# Tune RF\n\n# Create a function to evaluate AUC for a set of parameters\ntune_rf &lt;- function(mtry_val, min_node) {\n  rf_model &lt;- ranger(\n    y ~ ., data = train_df,\n    probability = TRUE,\n    num.trees = 500,\n    mtry = mtry_val,\n    min.node.size = min_node,\n    seed = 123\n  )\n  \n  rf_probs &lt;- predict(rf_model, data = test_df)$predictions[, \"Yes\"]\n  roc_obj &lt;- roc(y_test, rf_probs, quiet = TRUE)\n  auc_val &lt;- auc(roc_obj)\n  return(auc_val)\n}\n\n# Grid search over mtry and min.node.size\nresults &lt;- expand.grid(\n  mtry = c(5, 10, 20, 50),\n  min.node.size = c(1, 5, 10)\n)\n\nresults$AUC &lt;- mapply(tune_rf, results$mtry, results$min.node.size)\n\n# Find best combination\nbest_params &lt;- results[which.max(results$AUC), ]\nprint(best_params)\n\n# Refit final tuned Random Forest model with best hyperparameters\nfinal_rf_model &lt;- ranger(\n  y ~ ., data = train_df,\n  probability = TRUE,\n  num.trees = 500,\n  mtry = best_params$mtry,\n  min.node.size = best_params$min.node.size,\n  seed = 123\n)\n\n# Predict and evaluate\nfinal_rf_probs &lt;- predict(final_rf_model, data = test_df)$predictions[, \"Yes\"]\nfinal_rf_preds &lt;- ifelse(final_rf_probs &gt; 0.5, \"Yes\", \"No\")\n\n# Confusion matrix\nconf_matrix &lt;- table(Predicted = final_rf_preds, Actual = y_test)\nprint(conf_matrix)\n\n# Accuracy and AUC\naccuracy &lt;- sum(diag(conf_matrix)) / sum(conf_matrix)\nroc_obj &lt;- roc(y_test, final_rf_probs)\nauc_val &lt;- auc(roc_obj)\n\ncat(\"Tuned RF Accuracy:\", round(accuracy, 3), \"\\n\")\ncat(\"Tuned RF AUC:\", round(auc_val, 3), \"\\n\")",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Common steps</span>"
    ]
  }
]