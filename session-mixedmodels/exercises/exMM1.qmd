---
title: "Introduction to Mixed Models"
subtitle: "Exercises in R"
format:
  html:
    toc: true
    number-sections: true
    self-contained: true
execute:
  echo: true
  cache: false
---
  
# Introduction
  
Mixed effects models are powerful statistical tools that allow us to analyze data with hierarchical or grouped structures. In these exercises, we will explore the use of mixed models in R.
  
# Setup

You will be using the `lme4` package for fitting mixed models and you need to install this package. In the examples we will use `tidyverse` for data manipulation and `ggplot2` for visualization, but if you prefert other alternatives, that is of course fine.

```{r setup}
#| message: false
library(lme4)
library(tidyverse)
library(ggplot2)
```

# Random intercept and slope

In these exercises we cover both models with **random intercept** and **random slope** using the `lme4` package in R.

## Drug effect on blood pressure
  
A study investigates how a drug affects blood pressure. 200 patients are recruited at 10 hospitals. We suspect that the average blood pressure differs between hospitals, mainly due to different routines for measurement, but we expect the drug effect to be consistent.

```{r databp}
## Generate the data
databp <- data.frame(hospital=factor(rep(1:10, each=20)),
                 drug=rep(c("placebo", "treatment"), times=100),
                 bp=c(123.9,114.6,119.8,113.3,115.0,121.7,120.2,102.9,121.3,110.4,112.4,111.7,112.6,109.1,114.6,104.3,121.9,113.5,112.1,119.0,121.2,112.6,123.6,118.5,123.2,117.5,121.8,113.8,117.5,112.2,115.6,113.0,112.8,124.9,125.1,108.5,117.1,111.7,123.0,113.7,127.5,121.1,126.0,128.1,125.1,128.8,118.5,124.2,126.9,122.3,128.1,118.7,124.6,116.1,120.9,122.8,128.5,121.5,130.8,131.5,117.8,103.7,125.3,111.7,116.8,120.4,118.9,109.2,121.2,114.6,120.3,117.2,118.4,118.5,119.2,116.9,125.8,117.5,118.7,121.0,125.5,118.3,121.7,112.4,127.3,112.5,131.5,123.2,119.3,110.4,117.0,116.8,119.3,113.8,115.8,115.3,116.6,107.2,118.6,120.1,124.0,124.9,118.8,121.6,129.5,123.4,127.4,118.7,122.6,116.7,127.4,117.1,124.4,120.6,136.1,118.6,128.0,122.3,122.1,121.5,129.1,119.1,122.0,114.7,111.6,122.5,114.5,120.5,131.4,109.6,125.4,115.5,114.0,109.3,113.8,114.2,114.5,120.3,132.3,110.4,118.9,113.8,116.6,104.9,114.3,108.5,117.8,108.1,119.8,108.1,120.2,104.7,108.6,126.1,112.9,111.4,118.1,107.5,117.5,111.8,116.2,112.6,117.1,122.9,113.5,106.8,117.4,113.8,119.4,110.0,111.9,118.6,115.5,107.9,116.1,111.3,122.8,112.7,121.0,109.8,119.3,111.6,118.7,108.7,111.7,123.2,121.2,107.0,115.2,107.3,129.2,119.8,116.9,115.9,116.1,110.8,114.3,110.2,126.5,112.9))
```

Visualize the data using e.g. boxplots or jitter plots, both overall and by hospital.

:::{.callout-tip collapse="true"}
## Solution

```{r fig-bpoveral}
#| fig-cap: "Blood pressure vs drug treatment, overall"
## Blood pressure vs drug treatment, treat each measurement as independent
databp %>%
  ggplot(aes(x = drug, y = bp)) +
  geom_boxplot() +
  geom_jitter(width = 0.2, alpha = 0.5) +
  theme_bw()
```

```{r fig-bpperhospital}
#| fig-cap: "Blood pressure vs drug treatment, per hospital"
## Blood pressure per hospital and drug treatment
databp |>
  ggplot(aes(x = hospital, y = bp, color = drug)) +
  geom_boxplot() +
  geom_jitter(width = 0.2, alpha = 0.5) +
  theme_bw()
```
:::

Based on the plots, do you think there is variability in blood pressure across hospitals that has to be taken care of?

:::{.callout-tip collapse="true"}
Yes, the plots suggest that there is variability in blood pressure across hospitals. The boxplots show different medians each hospital, indicating that the baseline blood pressure differs between hospitals. This variability should be accounted for in our analysis.
:::

If not, we can fit a model without taking care of the grouping structure, such as an ordinary linear regression model.

Fit a linear regression model to the data with blood pressure as the response variable and drug treatment as the independent variable.

:::{.callout-tip collapse="true"}
## Solution

```{r bplm}
lm_model <- lm(bp ~ drug, data = databp)
summary(lm_model)
```
:::

According to the linear regression model, is the average blood pressure higher in the treatment group compared to the placebo group? By how much does the drug change the blood pressure (on average)?

:::{.callout-tip collapse="true"}
The average blood pressure is lower in the treatment group compared to the placebo group. The estimated effect of the drug treatment on blood pressure is approximately -5.17, indicating that patients treated with the drug have an average blood pressure that is 5.17 lower than those treated with the placebo.
:::

Is this a valid model given the data structure? Why/why not?

To account for the variability in blood pressure across hospitals, fit a mixed model with a random intercept for hospital. Random intercepts allow each hospital to have its own baseline blood pressure.

:::{.callout-tip collapse="true"}
## Solution

```{r bplmer1, results="hide"}
model1 <- lmer(bp ~ drug + (1 | hospital), data = databp)
summary(model1)
```
:::

In addition to the summary function, try `VarCorr` and `fixef`. The function `VarCorr` gives the varioance and correlation a model, including the variance explained by the random intercept for hospital. `fixef` computes the fixed effects of the model.

:::{.callout-tip collapse="true"}
## Code

```{r}
print(VarCorr(model1), comp="Variance")
fixef(model1)
```
:::

Based on the mixed model results, what is the estimated effect of the drug treatment on blood pressure?

:::{.callout-tip collapse="true"}
## Solution

The estimated effect of the drug treatment on blood pressure is -5.17.
:::

Based on the mixed model, how much variability in blood pressure is explained by hospital?

To compute the variability explained by the random intercept, we can use the variance component from `VarCorr`. The proportion of variance explained by the random effect, called the **intraclass correlation coefficient (ICC)**, can be calculated as:

```{r icc}
vc <- as.data.frame(VarCorr(model1))
icc <- vc$vcov[1] / (vc$vcov[1] + vc$vcov[2])
```

Based on the variance explain by the random intercept for hospital, do you think it is appropriate to use an ordinary linear regression model instead of a mixed model? Why or why not?

:::{.callout-tip collapse="true"}
The variability explained by the random intercept for hospital is substantial, indicating that there are significant differences in blood pressure between hospitals. This suggests that the ordinary linear regression is not appropriate.
:::

The random intercepts for each hospital can be computed using the `ranef` function. This gives us the deviations from the overall mean (as reported by the fixed effect intercept) for each hospital.

Compute the random effects using `ranef`. Note that `ranef` gives the deviations from the overall mean for each hospital.

:::{.callout-tip collapse="true"}
## Code

```{r bprandom}
ranef(model1)
```
:::

What would the average blood pressure be at hospital 3 for a patient treated with the placebo?

:::{.callout-tip collapse="true"}
## Solution

```{r}
fixef(model1)[1] + ranef(model1)$hospital[3,1]
```
:::


## Sleep study

The `sleepstudy` dataset from the `lme4` package contains data on reaction times of subjects measured over several days of sleep deprivation (not allowed more than 3h of sleep).

Days 0 and 1 are adaptation and training and will be excluded. Day 2 is baseline, but for simplicity we will rename it to 0.

We will initially work with a subset of the data from only 5 subjects.

```{r sleep}
##Remove the first two days (before baseline) and adjust Days to be 0 at baseline.
sleepall <- sleepstudy |> filter(Days>=2) |> mutate(Days=Days-2)
##Select a subset of 5 individuals
sleep <- sleepstudy |> filter(Subject %in% c(333, 334, 369, 349, 372), Days>=2) |> mutate(Days=Days-2)
```

Investigate the dataset. What columns are available etc? Plot the data, e.g. using ggplot and add a linear regression line to visualize the relationship between reaction time and days of sleep deprivation.

:::{.callout-tip collapse="true"}
## Code

```{r fig-lm}
#| fig-cap: "Reaction time vs Days of sleep deprivation"
#| fig-subcap:
#|  - "Overall"
#|  - "Per subject"
#| layout-ncol: 2
head(sleep, 12)
##Plot Reaction time vs days of sleep deprivation, treat all measurements as independent
sleep |> ggplot(aes(x=Days, y=Reaction)) + geom_point() + geom_smooth(method="lm", se=FALSE) + theme_bw() +
  labs(x = "Days of sleep deprivation",
       y = "Reaction time (ms)")
##Plot Reaction time vs days of sleep deprivation, treating each subject as a separate group
sleep |> ggplot(aes(x=Days, y=Reaction, color=Subject)) + geom_point() + geom_smooth(method="lm", se=FALSE) + 
  theme_bw() + theme(legend.position = "none") +
  labs(x = "Days of sleep deprivation",
       y = "Reaction time (ms)")
```
:::

Fit a linear model to the data, ignoring the individual differences.

:::{.callout-tip collapse="true"}
## Code

```{r sleeplm}
lm_sleep <- lm(Reaction ~ Days, data = sleep)
summary(lm_sleep)
```
:::

According to this model, how many milliseconds does reaction time increase per day of sleep deprivation?

:::{.callout-tip collapse="true"}
## Solution

The model estimates that reaction time increases by approximately 14.060 milliseconds per day of sleep deprivation.
:::

Fit a mixed model with a random intercept for each subject to account for individual differences in reaction time.

:::{.callout-tip collapse="true"}
## Code

```{r sleepmm1}
mm1_sleep <- lmer(Reaction ~ Days + (1 | Subject), data = sleep)
summary(mm1_sleep)
```
:::

According to this models, how many milliseconds does reaction time increase per day of sleep deprivation?

:::{.callout-tip collapse="true"}
## Solution

The model estimates that reaction time increases by approximately 14.060 milliseconds per day of sleep deprivation, which is the same as in the linear model.
:::

How much variability in reaction time is explained by individual differences?

:::{.callout-tip collapse="true"}
The variability in reaction time explained by individual differences can be assessed using the variance component from the random intercept; 278.9.
:::

Now, include the full dataset and redo the analyses, i.e. visualize and fit a mixed model with random intercept.

:::{.callout-tip collapse="true"}
## Code

```{r fig-sleepfull}
#| fig-cap: "Reaction time vs Days of sleep deprivation"
sleepall |> ggplot(aes(x=Days, y=Reaction, color=Subject)) + geom_point() + geom_smooth(method="lm", se=FALSE) + 
  theme_bw() + theme(legend.position = "none") +
  labs(x = "Days of sleep deprivation",
       y = "Reaction time (ms)")
```

```{r sleepall}
mm_sleepall <- lmer(Reaction ~ Days + (1 | Subject), data = sleepall)
summary(mm_sleepall)
```
:::

What is the estimated fixed effect of sleep deprivation on reaction time in the full dataset?

What is the estimated variability in reaction time explained by subject differences?

The plot suggests that also the slope varies between subjects, i.e. some subjects are more affected by sleep deprivation than others. Investigate this further by including a random slope for `Days` within `Subject`.

:::{.callout-tip collapse="true"}
## Code

```{r sleep-random-slope}
mm2_sleepall <- lmer(Reaction ~ Days + (Days | Subject), data = sleepall)
summary(mm2_sleepall)
```
:::

Based on the model with random slope, what is the average effect of sleep deprivation on reaction time? How does it compare to the model with only a random intercept?

Compute the random effects for the model with random slope using `ranef(mm2_sleepall)`.
What is the estimated effect of sleep deprivation on reaction time for subject 309?


## Orthodontic measurement over time

The `Orthodont` dataset from the `nlme` package contains orthodontic measurements of patients over time. The dataset includes measurements of the distance from the pituitary to the pterygomaxillary fissure (mm).

Use this dataset to study how the distance changes with age, accounting for individual differences in growth patterns. Also, take any relevant covariates into account.

```{r ortho, message=FALSE}
library(nlme)
data("Orthodont", package = "nlme")
```

Start by looking at the data table.

```{r}
summary(Orthodont)
```

Visualize the data.

:::{.callout-tip collapse="true"}
## Code 

```{r fig-orthodont, results="hide"}
Orthodont |> 
  ggplot(aes(x = age, y = distance, group = Subject, color = Sex)) +
  geom_line() +
  geom_point() + 
  xlab("Age (years)") +
  ylab("Distance (mm)") +
  theme_bw()
```
:::

What is the grouping structure in the data?

What covariates could be relevant to include in the model?

First, fit a linear model to the data, ignoring any groupings, but include relevant covariate.

Then, fit a mixed model taking the grouping structure into account. Use a random intercept for `Subject` to account for individual differences in growth patterns.

:::{.callout-tip collapse="true"}
## Code

The groups would be the individual subjects, and the covariates could be `age` and `Sex`.

```{r}
lmortho <- lm(distance ~ age + Sex, data=Orthodont)
summary(lmortho)
mmortho <- lmer(distance ~ age + Sex + (1 | Subject), data=Orthodont)
summary(mmortho)
```
:::

What is the estimated effect of age on distance in the linear model? How does it compare to the mixed model?

What is the estimated variability in distance explained by subject differences? Does this suggest that the random intercept is needed in the model?


<!-- ## Logistic mixed model: Infection risk in clinics -->

<!-- A medical study investigates whether a new hygiene protocol reduces infection rates in clinics. Data was collected from 20 clinics, with 15 patients per clinic. Each patient was either treated under **standard** or **new** protocol. The outcome is binary: whether the patient developed an infection (`1`) or not (`0`). It is suspected that the infection rate varies between clinics, but the effect of the hygiene protocol is assumed to be consistent. -->

<!-- ### Simulate data -->

<!-- ```{r logistic-data} -->
<!-- set.seed(123) -->
<!-- n_clinics <- 20 -->
<!-- patients_per_clinic <- 15 -->
<!-- total_patients <- n_clinics * patients_per_clinic -->

<!-- clinic <- factor(rep(1:n_clinics, each = patients_per_clinic)) -->
<!-- protocol <- factor(rep(sample(c("standard", "new"), total_patients, replace = TRUE), levels = c("standard", "new"))) -->
<!-- intercept <- -1     # baseline log-odds of infection -->
<!-- treatment_effect <- -1.2  # log-odds reduction with new protocol -->
<!-- clinic_re <- rnorm(n_clinics, mean = 0, sd = 0.7)  # random intercepts per clinic -->
<!-- logit_p <- intercept + treatment_effect * (protocol == "new") + clinic_re[as.integer(clinic)] -->
<!-- prob <- plogis(logit_p) -->
<!-- infection <- rbinom(total_patients, size = 1, prob = prob) -->

<!-- log_data <- data.frame(clinic, protocol, infection) -->
<!-- ``` -->

<!-- ### Explore data -->

<!-- - Summarize infection proportions per protocol, in a figure or table. -->
<!-- - Plot proportion infected by clinic. -->

<!-- ```{r fig-logistic} -->
<!-- log_data %>% -->
<!--   ggplot(aes(x = protocol, fill = as.factor(infection))) + -->
<!--   geom_bar(position = "fill") + -->
<!--   labs(y = "Proportion", fill = "Infection") + -->
<!--   theme_minimal() -->

<!-- log_data %>% -->
<!--   group_by(clinic, protocol) %>% -->
<!--   summarise(infection_rate = mean(infection), .groups = "drop") %>% -->
<!--   ggplot(aes(x = clinic, y = infection_rate, fill = protocol)) + -->
<!--   geom_bar(stat = "identity", position = "dodge") + -->
<!--   theme_minimal() + -->
<!--   labs(y = "Infection Rate", x = "Clinic") -->
<!-- ``` -->

<!-- ### Fit logistic models -->

<!-- - Fit a logistic regression model without random effects. -->
<!-- - Fit a logistic mixed-effects model with a random intercept for clinic. -->

<!-- ```{r logistic-models} -->
<!-- glm_model <- glm(infection ~ protocol, data = log_data, family = binomial) -->
<!-- summary(glm_model) -->

<!-- glmer_model <- glmer(infection ~ protocol + (1 | clinic), data = log_data, family = binomial) -->
<!-- summary(glmer_model) -->
<!-- ``` -->

<!-- ### Questions -->

<!-- - What is the estimated effect of the new hygiene protocol on the probability of infection? -->
<!-- - How does the inclusion of a random intercept for clinic affect the results? -->
<!-- - Compute the **odds ratio** for the protocol effect. -->
<!-- - How much **variation in infection risk** exists between clinics? -->

<!-- ```{r odds-ratio} -->
<!-- exp(fixef(glmer_model)) -->
<!-- ``` -->

